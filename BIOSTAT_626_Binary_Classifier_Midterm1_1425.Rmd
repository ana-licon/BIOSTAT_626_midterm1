---
title: "BIOSTAT 626 Midterm 1 Binary classifier - 1425"
author: "Ana Laura Licon"
date: "`r Sys.Date()`"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:\\Users\\anala\\Desktop\\BIOSTAT 626")
getwd()
```

```{r}
library(dplyr)
library(caret)

# step 1: Set working directory (knitr::opts_knit$set(root.dir = "") where testing and training files are saved.

# step 2: Load training and test data files
training.data <- read.table("training_data.txt", header=T)
testing.data <- read.table("test_data.txt", header=T)

# step 3: Make binary variable for static and dynamic activities
training.data <- training.data %>% mutate(BinaryClass = if_else(activity < 4 , 1, 0))

# step 4: Remove subject variables form the data sets, and the activity variable from the training data as I use the BinaryClass variable created in the last step
training.data <- select(training.data, -c(subject, activity))
testing.data <- select(testing.data, -subject)

# step 5: Set seed to 626 and create data partition for training and testing the binary classifier. 
set.seed(626)
indxtrain <- createDataPartition(y = training.data$BinaryClass, p= 0.8, list = FALSE) 
training <- training.data[indxtrain,]
testing <- training.data[-indxtrain,]

# step 6: run logistic models for binary classification 

## notes: I ran two logistic models. The first model only uses 4 of the 561 features, and the second model uses all given 561 features. The second model will give a perfect classification, but it will return an error due to multicollinearity. This is a problem of over-fitting  due to linear dependence of the features because the model is using variables all calculated from the time and frequency domain data of the sensors. In contrast, the first model returns a classifier with about 95% accuracy, using less than 1% of the given features and no issues with over fitting. The only way to be competitive on the leader board was to use the second model

glm.fit <- glm(BinaryClass~F1+F2+F3+F201,family=binomial, data=training)

glm.fit2 <- glm(BinaryClass~.,family=binomial, data=training)

# step 7: Make predictions with classifiers on subsetted training data to verify accuracy of classification

# prediction from first model, glm.fit
prediction.probs <- predict(glm.fit, testing, type="response") # get prediction probabilities 
predictions <- rep(0,length(prediction.probs)) # make prediction vector
predictions[prediction.probs >= 0.5] <- 1 # fill vector with predictions based on calculated probabilities
confusionMatrix(table(predictions, testing$BinaryClass)) # make confusion matrix to check accuracy of classification

# prediction from second model, glm.fit2
prediction.probs2 <- predict(glm.fit2, testing, type="response") # get prediction probabilities
predictions2 <- rep(0,length(prediction.probs2)) # make prediction vector
predictions2[prediction.probs2 >= 0.5] <- 1 # fill vector with predictions based on calculated probabilities
confusionMatrix(table(predictions2, testing$BinaryClass)) #  confusion matrix to check accuracy of classification

# step 8: make prediction on test data using model 2 (glm.fit2)
binary.probs <- predict(glm.fit2, testing.data, type="response") # get prediction probabilities
binary.preds <- rep(0,length(prediction.probs2)) # make prediction vector
binary.preds[binary.probs >= 0.5] <- 1 # make prediction vector

# step 9: write out binary classification predictions to a text file named ```binary_1425.txt```
write.table(binary.preds, "binary_1425.txt", row.names=FALSE, col.names=FALSE, quote = F)

```

